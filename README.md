# Image-Generation-using-GANs
Generative Adversarial Network which is popularly known as GANs is a deep learning, unsupervised machine learning technique which is proposed in year 2014.
The main blocks of this architecture are:

Generator : This block tries to generates the images which are very similar to that of original dataset by taking noise as input. It tries to learn the join probability of the input data (X) and output data(Y); P(X|Y).

Discriminator : This block tries to accept two inputs, one from main dataset and other from images generated from Generator, and bifurcates them as Real or Fake.

To make this Generative and Adversarial process simple, both these block are made from Deep Neural Network based architecture which can be trained through forward and backward propagation techniques.

The generator generates a "fake" sample given a random vector/matrix, and the discriminator attempts to detect whether a given sample is "real" (picked from the training data) or "fake" (generated by the generator). Training happens in tandem: we train the discriminator for a few epochs, then train the generator for a few epochs, and repeat. This way both the generator and the discriminator get better at doing their jobs.

## Discriminator Network
The discriminator takes an image as input, and tries to classify it as "real" or "generated". In this sense, it's like any other neural network. We'll use a convolutional neural networks (CNN) which outputs a single number output for every image. We'll use stride of 2 to progressively reduce the size of the output feature map.
 
## Generator Network
The input to the generator is typically a vector or a matrix of random numbers (referred to as a latent tensor) which is used as a seed for generating an image. The generator will convert a latent tensor of shape (128, 1, 1) into an image tensor of shape 3 x 28 x 28. To achive this, we'll use the ConvTranspose2d layer from PyTorch, which is performs to as a transposed convolution (also referred to as a deconvolution).

We use the TanH activation function for the output layer of the generator.
![image](https://user-images.githubusercontent.com/87022232/200118515-3e1abbf4-5a38-4f35-95f8-39f17f4e9b11.png)


## Discriminator Training
Since the discriminator is a binary classification model, we can use the binary cross entropy loss function to quantify how well it is able to differentiate between real and generated images.



Here are the steps involved in training the discriminator.

We expect the discriminator to output 1 if the image was picked from the real MNIST dataset, and 0 if it was generated using the generator network.

We first pass a batch of real images, and compute the loss, setting the target labels to 1.



## Generator Training
Since the outputs of the generator are images, it's not obvious how we can train the generator. This is where we employ a rather elegant trick, which is to use the discriminator as a part of the loss function. Here's how it works:

We generate a batch of images using the generator, pass the into the discriminator.

We calculate the loss by setting the target labels to 1 i.e. real. We do this because the generator's objective is to "fool" the discriminator.

We use the loss to perform gradient descent i.e. change the weights of the generator, so it gets better at generating real-like images to "fool" the discriminator.

Then we pass a batch of fake images (generated using the generator) pass them into the discriminator, and compute the loss, setting the target labels to 0.

Finally we add the two losses and use the overall loss to perform gradient descent to adjust the weights of the discriminator.

It's important to note that we don't change the weights of the generator model while training the discriminator (opt_d only affects the discriminator.parameters())


## Results
Image-0:
![image](https://user-images.githubusercontent.com/87022232/200119167-b5d0ccc5-cf91-43fb-80b2-c331e9ba8520.png)

Image 1: 
![image](https://user-images.githubusercontent.com/87022232/200119229-d152257b-7f52-4d22-b775-4ec5d7be1592.png)


Image 12:
![image](https://user-images.githubusercontent.com/87022232/200119247-fd50fe44-2ce0-4089-8bfc-47fc010a0e05.png)

Image 25:
![image](https://user-images.githubusercontent.com/87022232/200119263-73b6bc14-bc64-4166-aee4-925013d2af07.png)



## Fake vs Real Scores
![image](https://user-images.githubusercontent.com/87022232/200119294-350fe294-9f6a-4f0d-839f-4c8214381bf6.png)







